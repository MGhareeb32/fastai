{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2024-07-29 21:19:56--  https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.111.133, 185.199.109.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 1115394 (1.1M) [text/plain]\n",
      "Saving to: ‘input.txt’\n",
      "\n",
      "input.txt           100%[===================>]   1.06M  --.-KB/s    in 0.1s    \n",
      "\n",
      "2024-07-29 21:19:57 (10.3 MB/s) - ‘input.txt’ saved [1115394/1115394]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1115394"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('input.txt', 'r', encoding='utf-8')  as file:\n",
    "    text = file.read()\n",
    "len(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First Citizen:\n",
      "Before we proceed any further, hear me speak.\n",
      "\n",
      "All:\n",
      "Speak, speak.\n",
      "\n",
      "First Citizen:\n",
      "You\n"
     ]
    }
   ],
   "source": [
    "print(text[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n !$&',-.3:;?ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab = sorted(list(set(text)))\n",
    "''.join(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[61, 39, 64, 64, 39, 54]\n",
      "wazzap\n"
     ]
    }
   ],
   "source": [
    "ctoi = {c: i for i, c in enumerate(vocab)}\n",
    "itoc = {i: c for c, i in ctoi.items()}\n",
    "encode = lambda s: [ctoi[c] for c in s]\n",
    "decode = lambda l: ''.join([itoc[i] for i in l])\n",
    "\n",
    "print(encode('wazzap'))\n",
    "print(decode(encode('wazzap')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1115394]) <built-in method type of Tensor object at 0x7fe0f8030bd0>\n",
      "tensor([18, 47, 56, 57, 58,  1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 14, 43, 44,\n",
      "        53, 56, 43,  1, 61, 43,  1, 54, 56, 53, 41, 43, 43, 42,  1, 39, 52, 63,\n",
      "         1, 44, 59, 56, 58, 46, 43, 56,  6,  1, 46, 43, 39, 56,  1, 51, 43,  1,\n",
      "        57, 54, 43, 39, 49,  8,  0,  0, 13, 50, 50, 10,  0, 31, 54, 43, 39, 49,\n",
      "         6,  1, 57, 54, 43, 39, 49,  8,  0,  0, 18, 47, 56, 57, 58,  1, 15, 47,\n",
      "        58, 47, 64, 43, 52, 10,  0, 37, 53, 59])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "data = torch.tensor(encode(text), dtype=torch.long)\n",
    "print(data.shape, data.type)\n",
    "print(data[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = int(.9 * len(data))\n",
    "data_train = data[:n]\n",
    "data_test = data[n:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([18, 47, 56, 57, 58,  1, 15, 47, 58])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "block_size = 8\n",
    "data_train[:block_size+1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([18]) tensor(47)\n",
      "tensor([18, 47]) tensor(56)\n",
      "tensor([18, 47, 56]) tensor(57)\n",
      "tensor([18, 47, 56, 57]) tensor(58)\n",
      "tensor([18, 47, 56, 57, 58]) tensor(1)\n",
      "tensor([18, 47, 56, 57, 58,  1]) tensor(15)\n",
      "tensor([18, 47, 56, 57, 58,  1, 15]) tensor(47)\n",
      "tensor([18, 47, 56, 57, 58,  1, 15, 47]) tensor(58)\n"
     ]
    }
   ],
   "source": [
    "for i in range(block_size):\n",
    "    print(data_train[:i+1], data_train[i+1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[18, 47, 56, 57, 58,  1, 15, 47],\n",
       "         [18, 47, 56, 57, 58,  1, 15, 47],\n",
       "         [18, 47, 56, 57, 58,  1, 15, 47],\n",
       "         [18, 47, 56, 57, 58,  1, 15, 47]]),\n",
       " tensor([[47, 56, 57, 58,  1, 15, 47, 58],\n",
       "         [47, 56, 57, 58,  1, 15, 47, 58],\n",
       "         [47, 56, 57, 58,  1, 15, 47, 58],\n",
       "         [47, 56, 57, 58,  1, 15, 47, 58]]))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def gen_batch(data, block_size=8, batch_size=4):\n",
    "    ixs = torch.randint(high=len(data) - block_size, size=(batch_size,))\n",
    "    x = torch.stack([data[ix:ix+block_size] for ix in ixs])\n",
    "    y = torch.stack([data[ix+1:ix+block_size+1] for ix in ixs])\n",
    "    return x, y\n",
    "\n",
    "gen_batch(data_train[:8+1], 8, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[43, 56,  1, 21,  1, 46, 43, 39],\n",
       "         [21, 26, 19, 20, 13, 25, 10,  0],\n",
       "         [39, 52, 63,  1, 39, 52,  1, 46],\n",
       "         [56, 63,  1, 63, 53, 59,  1, 51]]),\n",
       " tensor([[56,  1, 21,  1, 46, 43, 39, 56],\n",
       "         [26, 19, 20, 13, 25, 10,  0, 32],\n",
       "         [52, 63,  1, 39, 52,  1, 46, 43],\n",
       "         [63,  1, 63, 53, 59,  1, 51, 43]]))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen_batch(data_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 8, 65])\n",
      "tensor(4.7214, grad_fn=<NllLossBackward0>)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'abcdefgh3FQ:yW$M'"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "class Bigram(nn.Module):\n",
    "    def __init__(self, vocab_size):\n",
    "        super().__init__()\n",
    "        self.embeds = nn.Embedding(vocab_size, vocab_size)\n",
    "\n",
    "    def forward(self, idx, targets=None):\n",
    "        logits = self.embeds(idx)\n",
    "\n",
    "        if targets is None:\n",
    "            loss = None\n",
    "        else:\n",
    "            B, T, C = logits.shape\n",
    "            loss = F.cross_entropy(\n",
    "                logits.view(B*T, C),\n",
    "                targets.view(B*T))\n",
    "\n",
    "        return logits, loss\n",
    "\n",
    "    def generate(self, idx, max_new_tokens):\n",
    "        # idx is BxT\n",
    "        for _ in range(max_new_tokens):\n",
    "            logits, loss = self(idx) # BxTxC\n",
    "            last_pred = logits[:,-1,:] # BxC\n",
    "            probs = F.softmax(last_pred, dim=-1) # BxC\n",
    "            idx_next = torch.multinomial(probs, num_samples=1) # Bx1\n",
    "            idx = torch.cat((idx, idx_next), dim=1) # Bx(T+1)\n",
    "        return idx\n",
    "\n",
    "\n",
    "model = Bigram(len(vocab))\n",
    "xb, yb = gen_batch(data_train)\n",
    "logits, loss = model(xb, yb)\n",
    "print(logits.shape)\n",
    "print(loss)\n",
    "\n",
    "decode(model.generate(torch.stack([torch.tensor(encode('abcdefgh'), dtype=torch.long)]), 8)[0].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.179408550262451\n",
      "3.20768666267395\n",
      "3.173722267150879\n",
      "2.641472339630127\n",
      "3.042167901992798\n",
      "2.951714515686035\n",
      "2.3903934955596924\n",
      "2.790316343307495\n",
      "2.5644607543945312\n",
      "2.7424395084381104\n"
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-3)\n",
    "\n",
    "batch_size = 64\n",
    "for i in range(10000):\n",
    "    xb, yb = gen_batch(data_train)\n",
    "    logits, loss = model(xb, yb)\n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    if i % 1000 == 999: print(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " sur e.\n",
      "wavIORI't oulll s t fougethyand he fay\n",
      "\n",
      "feve.\n",
      "Bu as, way, ar je mmangm'Ps in 'dans the, t lat\n"
     ]
    }
   ],
   "source": [
    "print(decode(model.generate(torch.stack([torch.tensor(encode(' '), dtype=torch.long)]), 100)[0].tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.3333],\n",
       "        [0.6667],\n",
       "        [1.0000]])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.tril(torch.ones(3, 3)) @ torch.tensor([\n",
    "    [1, 2],\n",
    "    [2, 2],\n",
    "    [2, 4],\n",
    "], dtype=torch.float)\n",
    "torch.mean(torch.tril(torch.ones(3, 3)), dim=1, keepdim=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
