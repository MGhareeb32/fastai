{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic TSDAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/msid/fastai/venv/lib/python3.10/site-packages/sentence_transformers/cross_encoder/CrossEncoder.py:11: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm, trange\n",
      "When tie_encoder_decoder=True, the decoder_name_or_path will be invalid.\n",
      "Some weights of BertLMHeadModel were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['bert.encoder.layer.0.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.0.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.0.crossattention.output.dense.bias', 'bert.encoder.layer.0.crossattention.output.dense.weight', 'bert.encoder.layer.0.crossattention.self.key.bias', 'bert.encoder.layer.0.crossattention.self.key.weight', 'bert.encoder.layer.0.crossattention.self.query.bias', 'bert.encoder.layer.0.crossattention.self.query.weight', 'bert.encoder.layer.0.crossattention.self.value.bias', 'bert.encoder.layer.0.crossattention.self.value.weight', 'bert.encoder.layer.1.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.1.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.1.crossattention.output.dense.bias', 'bert.encoder.layer.1.crossattention.output.dense.weight', 'bert.encoder.layer.1.crossattention.self.key.bias', 'bert.encoder.layer.1.crossattention.self.key.weight', 'bert.encoder.layer.1.crossattention.self.query.bias', 'bert.encoder.layer.1.crossattention.self.query.weight', 'bert.encoder.layer.1.crossattention.self.value.bias', 'bert.encoder.layer.1.crossattention.self.value.weight', 'bert.encoder.layer.10.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.10.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.10.crossattention.output.dense.bias', 'bert.encoder.layer.10.crossattention.output.dense.weight', 'bert.encoder.layer.10.crossattention.self.key.bias', 'bert.encoder.layer.10.crossattention.self.key.weight', 'bert.encoder.layer.10.crossattention.self.query.bias', 'bert.encoder.layer.10.crossattention.self.query.weight', 'bert.encoder.layer.10.crossattention.self.value.bias', 'bert.encoder.layer.10.crossattention.self.value.weight', 'bert.encoder.layer.11.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.11.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.11.crossattention.output.dense.bias', 'bert.encoder.layer.11.crossattention.output.dense.weight', 'bert.encoder.layer.11.crossattention.self.key.bias', 'bert.encoder.layer.11.crossattention.self.key.weight', 'bert.encoder.layer.11.crossattention.self.query.bias', 'bert.encoder.layer.11.crossattention.self.query.weight', 'bert.encoder.layer.11.crossattention.self.value.bias', 'bert.encoder.layer.11.crossattention.self.value.weight', 'bert.encoder.layer.2.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.2.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.2.crossattention.output.dense.bias', 'bert.encoder.layer.2.crossattention.output.dense.weight', 'bert.encoder.layer.2.crossattention.self.key.bias', 'bert.encoder.layer.2.crossattention.self.key.weight', 'bert.encoder.layer.2.crossattention.self.query.bias', 'bert.encoder.layer.2.crossattention.self.query.weight', 'bert.encoder.layer.2.crossattention.self.value.bias', 'bert.encoder.layer.2.crossattention.self.value.weight', 'bert.encoder.layer.3.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.3.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.3.crossattention.output.dense.bias', 'bert.encoder.layer.3.crossattention.output.dense.weight', 'bert.encoder.layer.3.crossattention.self.key.bias', 'bert.encoder.layer.3.crossattention.self.key.weight', 'bert.encoder.layer.3.crossattention.self.query.bias', 'bert.encoder.layer.3.crossattention.self.query.weight', 'bert.encoder.layer.3.crossattention.self.value.bias', 'bert.encoder.layer.3.crossattention.self.value.weight', 'bert.encoder.layer.4.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.4.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.4.crossattention.output.dense.bias', 'bert.encoder.layer.4.crossattention.output.dense.weight', 'bert.encoder.layer.4.crossattention.self.key.bias', 'bert.encoder.layer.4.crossattention.self.key.weight', 'bert.encoder.layer.4.crossattention.self.query.bias', 'bert.encoder.layer.4.crossattention.self.query.weight', 'bert.encoder.layer.4.crossattention.self.value.bias', 'bert.encoder.layer.4.crossattention.self.value.weight', 'bert.encoder.layer.5.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.5.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.5.crossattention.output.dense.bias', 'bert.encoder.layer.5.crossattention.output.dense.weight', 'bert.encoder.layer.5.crossattention.self.key.bias', 'bert.encoder.layer.5.crossattention.self.key.weight', 'bert.encoder.layer.5.crossattention.self.query.bias', 'bert.encoder.layer.5.crossattention.self.query.weight', 'bert.encoder.layer.5.crossattention.self.value.bias', 'bert.encoder.layer.5.crossattention.self.value.weight', 'bert.encoder.layer.6.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.6.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.6.crossattention.output.dense.bias', 'bert.encoder.layer.6.crossattention.output.dense.weight', 'bert.encoder.layer.6.crossattention.self.key.bias', 'bert.encoder.layer.6.crossattention.self.key.weight', 'bert.encoder.layer.6.crossattention.self.query.bias', 'bert.encoder.layer.6.crossattention.self.query.weight', 'bert.encoder.layer.6.crossattention.self.value.bias', 'bert.encoder.layer.6.crossattention.self.value.weight', 'bert.encoder.layer.7.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.7.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.7.crossattention.output.dense.bias', 'bert.encoder.layer.7.crossattention.output.dense.weight', 'bert.encoder.layer.7.crossattention.self.key.bias', 'bert.encoder.layer.7.crossattention.self.key.weight', 'bert.encoder.layer.7.crossattention.self.query.bias', 'bert.encoder.layer.7.crossattention.self.query.weight', 'bert.encoder.layer.7.crossattention.self.value.bias', 'bert.encoder.layer.7.crossattention.self.value.weight', 'bert.encoder.layer.8.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.8.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.8.crossattention.output.dense.bias', 'bert.encoder.layer.8.crossattention.output.dense.weight', 'bert.encoder.layer.8.crossattention.self.key.bias', 'bert.encoder.layer.8.crossattention.self.key.weight', 'bert.encoder.layer.8.crossattention.self.query.bias', 'bert.encoder.layer.8.crossattention.self.query.weight', 'bert.encoder.layer.8.crossattention.self.value.bias', 'bert.encoder.layer.8.crossattention.self.value.weight', 'bert.encoder.layer.9.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.9.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.9.crossattention.output.dense.bias', 'bert.encoder.layer.9.crossattention.output.dense.weight', 'bert.encoder.layer.9.crossattention.self.key.bias', 'bert.encoder.layer.9.crossattention.self.key.weight', 'bert.encoder.layer.9.crossattention.self.query.bias', 'bert.encoder.layer.9.crossattention.self.query.weight', 'bert.encoder.layer.9.crossattention.self.value.bias', 'bert.encoder.layer.9.crossattention.self.value.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "The following encoder weights were not tied to the decoder ['bert/pooler']\n",
      "We strongly recommend passing in an `attention_mask` since your input_ids may be padded. See https://huggingface.co/docs/transformers/troubleshooting#incorrect-output-when-padding-tokens-arent-masked.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3/3 00:00, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "!pip install -Uqq sentence_transformers\n",
    "\n",
    "from sentence_transformers import SentenceTransformer, LoggingHandler\n",
    "from sentence_transformers import models, util, datasets, evaluation, losses\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "model_name = \"bert-base-uncased\"\n",
    "word_embedding_model = models.Transformer(model_name)\n",
    "pooling_model = models.Pooling(word_embedding_model.get_word_embedding_dimension(), \"cls\")\n",
    "model = SentenceTransformer(modules=[word_embedding_model, pooling_model])\n",
    "\n",
    "train_sentences = [\n",
    "    \"Your set of sentences\",\n",
    "    \"Model will automatically add the noise\",\n",
    "    \"And re-construct it\",\n",
    "    \"You should provide at least 1k sentences\",\n",
    "]\n",
    "\n",
    "train_dataset = datasets.DenoisingAutoEncoderDataset(train_sentences)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
    "train_loss = losses.DenoisingAutoEncoderLoss(\n",
    "    model, decoder_name_or_path=model_name, tie_encoder_decoder=True\n",
    ")\n",
    "\n",
    "model.fit(\n",
    "    train_objectives=[(train_dataloader, train_loss)],\n",
    "    epochs=3,\n",
    "    weight_decay=0,\n",
    "    scheduler=\"constantlr\",\n",
    "    optimizer_params={\"lr\": 3e-5},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 768)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[1.0000, 0.9208, 0.8642],\n",
       "        [0.9208, 1.0000, 0.9015],\n",
       "        [0.8642, 0.9015, 1.0000]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences = [\n",
    "    \"The weather is lovely today.\",\n",
    "    \"It's so sunny outside!\",\n",
    "    \"Why is it raining?\",\n",
    "]\n",
    "embeddings = model.encode(sentences)\n",
    "print(embeddings.shape)\n",
    "model.similarity(embeddings, embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load NYUAD sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# sent_id = 20000715_AFP_ARB.0001:3\n",
      "# text = وبدا ستيفن كنت نحيلا جدا ، الا انه اغتسل وحلق ذقنه للمرة الاولى منذ فترة لا بد ان تكون طويلة . وبما ان المناسبة تستحق العناء اشترى سروالا ازرق وحذاء جديدين ومعطفا خفيفا ليبدا بها حياته الجديدة .\n",
      "# text_bw = wbdA styfn knt nHylA jdA , AlA Anh Agtsl wHlq *qnh llmrp AlAwlY mn* ftrp lA bd An tkwn Twylp . wbmA An AlmnAsbp tstHq AlEnA' A$trY srwAlA Azrq wH*A' jdydyn wmETfA xfyfA lybdA bhA HyAth Aljdydp .\n",
      "1-2\tوبدا\t_\t_\t_\t_\t_\t_\t_\t_\n",
      "1\tو\tw\tCCONJ\tCONJ\t_\t2\tcc\t_\tbw=wa\n",
      "2\tبدا\tbadA-u_1\tVERB\tPV+PVSUFF_SUBJ:3MS\tAspect=Perf|Gender=Masc|Mood=Ind|Number=Sing|Person=3|Voice=Act\t0\troot\t_\tbw=badA\n",
      "3\tستيفن\tstiyfin_1\tPROPN\tNOUN_PROP\tDefinite=Ind|Gender=Masc|Number=Sing\t2\tnsubj\t_\tbw=stiyfin\n",
      "4\tكنت\tkinot_1\tPROPN\tNOUN_PROP\tDefinite=Ind|Gender=Masc|Number=Sing\t3\tflat\t_\tbw=kinot\n",
      "5\tنحيلا\tnaHiyl_1\tADJ\tADJ+CASE_INDEF_ACC\tCase=Acc|Definite=Ind|Gender=Masc|Number=Sing\t2\tamod\t_\tbw=naHiylAF\n",
      "6\tجدا\tjid~_1\tNOUN\tNOUN+CASE_INDEF_ACC\tCase=Acc|Definite=Ind|Gender=Masc|Number=Sing\t5\tnmod\t_\tbw=jid~AF\n",
      "7\t،\tDEFAULT\tPUNCT\tPUNC\t_\t2\tpunct\t_\tbw=,\n",
      "8\tالا\t<il~A_2\tADP\tPREP\tAdpType=Prep\t10\tcase\t_\tbw=<il~A\n",
      "9-10\tانه\t_\t_\t_\t_\t_\t_\t_\t_\n",
      "9\tان\t>an~a_1\tSCONJ\tSUB_CONJ\t_\t10\tmark\t_\tbw=>an~a\n",
      "10\tه\th\tPRON\tPRON_3MS\tDefinite=Def|Gender=Masc|Number=Sing|Person=3|PronType=Prs\t2\tobj\t_\tbw=hu\n",
      "11\tاغتسل\t{igotasal_1\tVERB\tPV+PVSUFF_SUBJ:3MS\tAspect=Perf|Gender=Masc|Mood=Ind|Number=Sing|Person=3|Voice=Act\t10\tccomp\t_\tbw={igotasala\n",
      "12-13\tوحلق\t_\t_\t_\t_\t_\t_\t_\t_\n",
      "12\tو\tw\tCCONJ\tCONJ\t_\t13\tcc\t_\tbw=wa\n",
      "13\tحلق\tHalaq-i_1\tVERB\tPV+PVSUFF_SUBJ:3MS\tAspect=Perf|Gender=Masc|Mood=Ind|Number=Sing|Person=3|Voice=Act\t10\tccomp\t_\tbw=Halaqa\n",
      "14-15\tذقنه\t_\t_\t_\t_\t_\t_\t_\t_\n",
      "14\tذقن\t*aqon_1\tNOUN\tNOUN+CASE_DEF_ACC\tCase=Acc|Definite=Com|Gender=Masc|Number=Sing\t13\tobj\t_\tbw=*aqona\n",
      "15\tه\th\tPRON\tPOSS_PRON_3MS\tCase=Gen|Definite=Def|Gender=Masc|Number=Sing|Person=3|PronType=Prs\t14\tnmod:poss\t_\tbw=hu\n",
      "16-17\tللمرة\t_\t_\t_\t_\t_\t_\t_\t_\n",
      "16\tل\tl\tADP\tPREP\tAdpType=Prep\t17\tcase\t_\tbw=li\n",
      "17\tلمرة\tmar~ap_1\tNOUN\tDET+NOUN+NSUFF_FEM_SG+CASE_DEF_GEN\tCase=Gen|Definite=Def|Gender=Fem|Number=Sing\t13\tiobj\t_\tbw=Almar~api\n",
      "18\tالاولى\t>aw~al_2\tADJ\tDET+ADJ_NUM\tDefinite=Def|Gender=Masc|Number=Sing\t17\tamod\t_\tbw=Al>uwlaY\n",
      "19\tمنذ\tmuno*u_1\tADP\tPREP\tAdpType=Prep\t20\tcase\t_\tbw=muno*u\n",
      "20\tفترة\tfatorap_1\tNOUN\tNOUN+NSUFF_FEM_SG+CASE_INDEF_GEN\tCase=Gen|Definite=Ind|Gender=Fem|Number=Sing\t17\tobj\t_\tbw=fatorapK\n",
      "21\tلا\tlA_3\tSCONJ\tPSEUDO_VERB\t_\t22\tmark\t_\tbw=lA\n",
      "22\tبد\tbud~_1\tNOUN\tNOUN+CASE_DEF_ACC\tCase=Acc|Definite=Com|Gender=Masc|Number=Sing\t20\tnmod\t_\tbw=bud~a\n",
      "23\tان\t>ano_1\tSCONJ\tSUB_CONJ\t_\t25\tmark\t_\tbw=>ano\n",
      "24\tتكون\tkAn-u_1\tAUX\tIV3FS+IV+IVSUFF_MOOD:S\tGender=Fem|Mood=Sub|Number=Sing|Person=3|Voice=Act\t25\tcop\t_\tbw=takuwna\n",
      "25\tطويلة\tTawiyl_1\tADJ\tADJ+NSUFF_FEM_SG+CASE_INDEF_ACC\tCase=Acc|Definite=Ind|Gender=Fem|Number=Sing\t22\tobj\t_\tbw=TawiylapF\n",
      "26\t.\tDEFAULT\tPUNCT\tPUNC\t_\t2\tpunct\t_\tbw=.\n",
      "27-29\tوبما\t_\t_\t_\t_\t_\t_\t_\t_\n",
      "27\tو\tw\tCCONJ\tCONJ\t_\t34\tcc\t_\tbw=wa\n",
      "28\tب\tb\tADP\tPREP\tAdpType=Prep\t32\tcase\t_\tbw=bi\n",
      "29\tما\tmA_4\tSCONJ\tSUB_CONJ\t_\t32\tmark\t_\tbw=mA\n",
      "30\tان\t>an~a_1\tSCONJ\tSUB_CONJ\t_\t32\tmark\t_\tbw=>an~a\n",
      "31\tالمناسبة\tmunAsabap_1\tNOUN\tDET+NOUN+NSUFF_FEM_SG+CASE_DEF_ACC\tCase=Acc|Definite=Def|Gender=Fem|Number=Sing\t32\tnsubj\t_\tbw=AlmunAsabapa\n",
      "32\tتستحق\t{isotaHaq~_1\tVERB\tIV3FS+IV+IVSUFF_MOOD:I\tAspect=Imp|Gender=Fem|Mood=Ind|Number=Sing|Person=3|Voice=Act\t34\tccomp\t_\tbw=tasotaHiq~u\n",
      "33\tالعناء\tEanA'_1\tNOUN\tDET+NOUN+CASE_DEF_ACC\tCase=Acc|Definite=Def|Gender=Masc|Number=Sing\t32\tobj\t_\tbw=AlEanA'a\n",
      "34\tاشترى\t{i$otaraY_1\tVERB\tPV+PVSUFF_SUBJ:3MS\tAspect=Perf|Gender=Masc|Mood=Ind|Number=Sing|Person=3|Voice=Act\t2\tccomp\t_\tbw={i$otaraY\n",
      "35\tسروالا\tsirowAl_1\tNOUN\tNOUN+CASE_INDEF_ACC\tCase=Acc|Definite=Ind|Gender=Masc|Number=Sing\t34\tobj\t_\tbw=sirowAlAF\n",
      "36\tازرق\t>azoraq_1\tADJ\tNOUN+CASE_INDEF_ACC\tCase=Acc|Definite=Ind|Gender=Masc|Number=Sing\t35\tamod\t_\tbw=>azoraqa\n",
      "37-38\tوحذاء\t_\t_\t_\t_\t_\t_\t_\t_\n",
      "37\tو\tw\tCCONJ\tCONJ\t_\t38\tcc\t_\tbw=wa\n",
      "38\tحذاء\tHi*A'_1\tNOUN\tNOUN+CASE_INDEF_ACC\tCase=Acc|Definite=Ind|Gender=Masc|Number=Sing\t35\tobj\t_\tbw=Hi*A'F\n",
      "39\tجديدين\tjadiyd_1\tADJ\tADJ+NSUFF_MASC_DU_ACC\tCase=Acc|Definite=Ind|Gender=Masc|Number=Dual\t35\tamod\t_\tbw=jadiydayoni\n",
      "40-41\tومعطفا\t_\t_\t_\t_\t_\t_\t_\t_\n",
      "40\tو\tw\tCCONJ\tCONJ\t_\t41\tcc\t_\tbw=wa\n",
      "41\tمعطفا\tmiEoTaf_1\tNOUN\tNOUN+CASE_INDEF_ACC\tCase=Acc|Definite=Ind|Gender=Masc|Number=Sing\t35\tobj\t_\tbw=miEoTafAF\n",
      "42\tخفيفا\txafiyf_1\tADJ\tADJ+CASE_INDEF_ACC\tCase=Acc|Definite=Ind|Gender=Masc|Number=Sing\t41\tamod\t_\tbw=xafiyfAF\n",
      "43-44\tليبدا\t_\t_\t_\t_\t_\t_\t_\t_\n",
      "43\tل\tl\tADP\tPREP\tAdpType=Prep\t44\tcase\t_\tbw=li\n",
      "44\tيبدا\tbada>-a_1\tVERB\tIV3MS+IV+IVSUFF_MOOD:S\tAspect=Imp|Gender=Masc|Mood=Sub|Number=Sing|Person=3|Voice=Act\t34\txcomp\t_\tbw=yaboda>a\n",
      "45-46\tبها\t_\t_\t_\t_\t_\t_\t_\t_\n",
      "45\tب\tbi_1\tADP\tPREP\tAdpType=Prep\t46\tcase\t_\tbw=bi\n",
      "46\tها\thA\tPRON\tPRON_3FS\tDefinite=Def|Gender=Fem|Number=Sing|Person=3|PronType=Prs\t44\tobj\t_\tbw=hA\n",
      "47-48\tحياته\t_\t_\t_\t_\t_\t_\t_\t_\n",
      "47\tحيات\tHayAp_1\tNOUN\tNOUN+NSUFF_FEM_SG+CASE_DEF_ACC\tCase=Acc|Definite=Com|Gender=Fem|Number=Sing\t44\tiobj\t_\tbw=HayAata\n",
      "48\tه\th\tPRON\tPOSS_PRON_3MS\tCase=Gen|Definite=Def|Gender=Masc|Number=Sing|Person=3|PronType=Prs\t47\tnmod:poss\t_\tbw=hu\n",
      "49\tالجديدة\tjadiyd_1\tADJ\tDET+ADJ+NSUFF_FEM_SG+CASE_DEF_ACC\tCase=Acc|Definite=Def|Gender=Fem|Number=Sing\t47\tamod\t_\tbw=Aljadiydapa\n",
      "50\t.\tDEFAULT\tPUNCT\tPUNC\t_\t2\tpunct\t_\tbw=.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!pip3 install -Uqq conllu tabulate\n",
    "import conllu\n",
    "from collections import defaultdict\n",
    "import pandas as pd\n",
    "with open('dev.conllu', 'r') as file:\n",
    "    corpus = conllu.parse(file.read())\n",
    "dbg_sent = corpus[2]\n",
    "print(dbg_sent.serialize())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def query_subtree(node, callback_fn=None, depth=0, parent=None):\n",
    "    total_size = 1\n",
    "    total_ids = set([node.token['id']])\n",
    "    for ch in node.children:\n",
    "        size, ids = query_subtree(ch, callback_fn, depth+1, node)\n",
    "        total_size += size\n",
    "        total_ids = total_ids.union(ids)\n",
    "    is_conseq = total_size == len(total_ids) and total_size == (max(total_ids) - min(total_ids) + 1)\n",
    "    if is_conseq and callback_fn is not None:\n",
    "        callback_fn(total_ids)\n",
    "    return total_size, total_ids\n",
    "\n",
    "def sent_text(sent, ids):\n",
    "    ans = []\n",
    "    watermark = -1\n",
    "    for t in sent:\n",
    "        id = t['id']\n",
    "        if type(id) is int:\n",
    "            if id not in ids or id <= watermark:\n",
    "                continue\n",
    "            ans.append(t['form'])\n",
    "        else:\n",
    "            id0, _, id1 = id\n",
    "            if id0 not in ids and id1 not in ids:\n",
    "                continue\n",
    "            conc = []\n",
    "            for lil_t in sent.filter(id=lambda x: type(x) is int and x >= id0 and x <= id1 and x in ids):\n",
    "                conc.append(lil_t['form'])\n",
    "                watermark = lil_t['id']\n",
    "            ans.append(''.join(conc))\n",
    "    return ' '.join(ans)\n",
    "\n",
    "def extract_sentences_of_len(sent, len_range, output):\n",
    "    def extract(ids):\n",
    "        if len(ids) < len_range[0] or len(ids) >= len_range[1]:\n",
    "            return\n",
    "        res = sent.filter(id=lambda x: x in ids)\n",
    "        res.metadata['text'] = sent_text(sent, ids)\n",
    "        output.append(res)\n",
    "    return extract\n",
    "\n",
    "def sent_to_pos(sent):\n",
    "    return ' '.join([t['upos'] for t in sent])\n",
    "\n",
    "DBG_SENT_COUNT = 9\n",
    "DBG_SENT_LEN = (4, 5)\n",
    "\n",
    "dbg_output = []\n",
    "_, _ = query_subtree(\n",
    "    dbg_sent.to_tree(),\n",
    "    extract_sentences_of_len(dbg_sent, DBG_SENT_LEN, dbg_output))\n",
    "[(s.metadata['text'], sent_to_pos(s)) for s in dbg_output]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2942\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('( الولايات المتحدة )', 'PUNCT NOUN ADJ PUNCT'),\n",
       " ('( اف ب )', 'PUNCT PROPN PROPN PUNCT'),\n",
       " ('ورث 300 الف دولار', 'VERB NUM NUM NOUN'),\n",
       " ('( 45 عاما )', 'PUNCT NUM NOUN PUNCT'),\n",
       " ('( شمال شرق )', 'PUNCT NOUN NOUN PUNCT'),\n",
       " ('تجوب كل الولايات الاميركية', 'VERB NOUN NOUN ADJ'),\n",
       " ('وهو يصعد الباص', 'CCONJ PRON VERB NOUN'),\n",
       " ('زجاجات النبيذ والبيرة', 'NOUN NOUN CCONJ NOUN'),\n",
       " ('في كونتية لوس انجليس', 'ADP NOUN PROPN PROPN')]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "short_sentences = []\n",
    "for sent in corpus:\n",
    "    query_subtree(\n",
    "        sent.to_tree(),\n",
    "        extract_sentences_of_len(sent, DBG_SENT_LEN, short_sentences))\n",
    "print(len(short_sentences))\n",
    "[(s.metadata['text'], sent_to_pos(s)) for s in short_sentences[:DBG_SENT_COUNT]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "When tie_encoder_decoder=True, the decoder_name_or_path will be invalid.\n",
      "Some weights of BertLMHeadModel were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['bert.encoder.layer.0.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.0.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.0.crossattention.output.dense.bias', 'bert.encoder.layer.0.crossattention.output.dense.weight', 'bert.encoder.layer.0.crossattention.self.key.bias', 'bert.encoder.layer.0.crossattention.self.key.weight', 'bert.encoder.layer.0.crossattention.self.query.bias', 'bert.encoder.layer.0.crossattention.self.query.weight', 'bert.encoder.layer.0.crossattention.self.value.bias', 'bert.encoder.layer.0.crossattention.self.value.weight', 'bert.encoder.layer.1.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.1.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.1.crossattention.output.dense.bias', 'bert.encoder.layer.1.crossattention.output.dense.weight', 'bert.encoder.layer.1.crossattention.self.key.bias', 'bert.encoder.layer.1.crossattention.self.key.weight', 'bert.encoder.layer.1.crossattention.self.query.bias', 'bert.encoder.layer.1.crossattention.self.query.weight', 'bert.encoder.layer.1.crossattention.self.value.bias', 'bert.encoder.layer.1.crossattention.self.value.weight', 'bert.encoder.layer.10.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.10.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.10.crossattention.output.dense.bias', 'bert.encoder.layer.10.crossattention.output.dense.weight', 'bert.encoder.layer.10.crossattention.self.key.bias', 'bert.encoder.layer.10.crossattention.self.key.weight', 'bert.encoder.layer.10.crossattention.self.query.bias', 'bert.encoder.layer.10.crossattention.self.query.weight', 'bert.encoder.layer.10.crossattention.self.value.bias', 'bert.encoder.layer.10.crossattention.self.value.weight', 'bert.encoder.layer.11.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.11.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.11.crossattention.output.dense.bias', 'bert.encoder.layer.11.crossattention.output.dense.weight', 'bert.encoder.layer.11.crossattention.self.key.bias', 'bert.encoder.layer.11.crossattention.self.key.weight', 'bert.encoder.layer.11.crossattention.self.query.bias', 'bert.encoder.layer.11.crossattention.self.query.weight', 'bert.encoder.layer.11.crossattention.self.value.bias', 'bert.encoder.layer.11.crossattention.self.value.weight', 'bert.encoder.layer.2.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.2.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.2.crossattention.output.dense.bias', 'bert.encoder.layer.2.crossattention.output.dense.weight', 'bert.encoder.layer.2.crossattention.self.key.bias', 'bert.encoder.layer.2.crossattention.self.key.weight', 'bert.encoder.layer.2.crossattention.self.query.bias', 'bert.encoder.layer.2.crossattention.self.query.weight', 'bert.encoder.layer.2.crossattention.self.value.bias', 'bert.encoder.layer.2.crossattention.self.value.weight', 'bert.encoder.layer.3.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.3.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.3.crossattention.output.dense.bias', 'bert.encoder.layer.3.crossattention.output.dense.weight', 'bert.encoder.layer.3.crossattention.self.key.bias', 'bert.encoder.layer.3.crossattention.self.key.weight', 'bert.encoder.layer.3.crossattention.self.query.bias', 'bert.encoder.layer.3.crossattention.self.query.weight', 'bert.encoder.layer.3.crossattention.self.value.bias', 'bert.encoder.layer.3.crossattention.self.value.weight', 'bert.encoder.layer.4.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.4.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.4.crossattention.output.dense.bias', 'bert.encoder.layer.4.crossattention.output.dense.weight', 'bert.encoder.layer.4.crossattention.self.key.bias', 'bert.encoder.layer.4.crossattention.self.key.weight', 'bert.encoder.layer.4.crossattention.self.query.bias', 'bert.encoder.layer.4.crossattention.self.query.weight', 'bert.encoder.layer.4.crossattention.self.value.bias', 'bert.encoder.layer.4.crossattention.self.value.weight', 'bert.encoder.layer.5.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.5.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.5.crossattention.output.dense.bias', 'bert.encoder.layer.5.crossattention.output.dense.weight', 'bert.encoder.layer.5.crossattention.self.key.bias', 'bert.encoder.layer.5.crossattention.self.key.weight', 'bert.encoder.layer.5.crossattention.self.query.bias', 'bert.encoder.layer.5.crossattention.self.query.weight', 'bert.encoder.layer.5.crossattention.self.value.bias', 'bert.encoder.layer.5.crossattention.self.value.weight', 'bert.encoder.layer.6.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.6.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.6.crossattention.output.dense.bias', 'bert.encoder.layer.6.crossattention.output.dense.weight', 'bert.encoder.layer.6.crossattention.self.key.bias', 'bert.encoder.layer.6.crossattention.self.key.weight', 'bert.encoder.layer.6.crossattention.self.query.bias', 'bert.encoder.layer.6.crossattention.self.query.weight', 'bert.encoder.layer.6.crossattention.self.value.bias', 'bert.encoder.layer.6.crossattention.self.value.weight', 'bert.encoder.layer.7.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.7.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.7.crossattention.output.dense.bias', 'bert.encoder.layer.7.crossattention.output.dense.weight', 'bert.encoder.layer.7.crossattention.self.key.bias', 'bert.encoder.layer.7.crossattention.self.key.weight', 'bert.encoder.layer.7.crossattention.self.query.bias', 'bert.encoder.layer.7.crossattention.self.query.weight', 'bert.encoder.layer.7.crossattention.self.value.bias', 'bert.encoder.layer.7.crossattention.self.value.weight', 'bert.encoder.layer.8.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.8.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.8.crossattention.output.dense.bias', 'bert.encoder.layer.8.crossattention.output.dense.weight', 'bert.encoder.layer.8.crossattention.self.key.bias', 'bert.encoder.layer.8.crossattention.self.key.weight', 'bert.encoder.layer.8.crossattention.self.query.bias', 'bert.encoder.layer.8.crossattention.self.query.weight', 'bert.encoder.layer.8.crossattention.self.value.bias', 'bert.encoder.layer.8.crossattention.self.value.weight', 'bert.encoder.layer.9.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.9.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.9.crossattention.output.dense.bias', 'bert.encoder.layer.9.crossattention.output.dense.weight', 'bert.encoder.layer.9.crossattention.self.key.bias', 'bert.encoder.layer.9.crossattention.self.key.weight', 'bert.encoder.layer.9.crossattention.self.query.bias', 'bert.encoder.layer.9.crossattention.self.query.weight', 'bert.encoder.layer.9.crossattention.self.value.bias', 'bert.encoder.layer.9.crossattention.self.value.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "The following encoder weights were not tied to the decoder ['bert/pooler']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='368' max='368' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [368/368 00:38, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer, LoggingHandler\n",
    "from sentence_transformers import models, util, datasets, evaluation, losses\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "model_name = \"bert-base-uncased\"\n",
    "word_embedding_model = models.Transformer(model_name)\n",
    "pooling_model = models.Pooling(word_embedding_model.get_word_embedding_dimension(), \"cls\")\n",
    "model = SentenceTransformer(modules=[word_embedding_model, pooling_model])\n",
    "\n",
    "train_dataset = datasets.DenoisingAutoEncoderDataset([sent_to_pos(s) for s in short_sentences])\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
    "train_loss = losses.DenoisingAutoEncoderLoss(\n",
    "    model, decoder_name_or_path=model_name, tie_encoder_decoder=True\n",
    ")\n",
    "\n",
    "model.fit(\n",
    "    train_objectives=[(train_dataloader, train_loss)],\n",
    "    epochs=1,\n",
    "    weight_decay=0,\n",
    "    scheduler=\"constantlr\",\n",
    "    optimizer_params={\"lr\": 3e-5},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2942, 768)\n",
      "( الولايات المتحدة )\n",
      "( اف ب )\n",
      "ورث 300 الف دولار\n",
      "( 45 عاما )\n",
      "( شمال شرق )\n",
      "تجوب كل الولايات الاميركية\n",
      "وهو يصعد الباص\n",
      "زجاجات النبيذ والبيرة\n",
      "في كونتية لوس انجليس\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[1.0000, 0.9208, 0.8642],\n",
       "        [0.9208, 1.0000, 0.9015],\n",
       "        [0.8642, 0.9015, 1.0000]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "short_sentences_embedded = model.encode(list(map(sent_to_pos, short_sentences)))\n",
    "print(short_sentences_embedded.shape)\n",
    "\n",
    "print('\\n'.join([s.metadata['text'] for s in short_sentences[:DBG_SENT_COUNT]]))\n",
    "model.similarity(embeddings[:DBG_SENT_COUNT,:], embeddings[:DBG_SENT_COUNT,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cluster Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-2 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-2 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-2 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-2 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-2 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-2 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>HDBSCAN()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;HDBSCAN<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.cluster.HDBSCAN.html\">?<span>Documentation for HDBSCAN</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>HDBSCAN()</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "HDBSCAN()"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.cluster import HDBSCAN\n",
    "\n",
    "hdb = HDBSCAN()\n",
    "hdb.fit(short_sentences_embedded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "clusters = defaultdict(lambda: [])\n",
    "for sent, prob, label in zip(short_sentences, hdb.probabilities_, hdb.labels_):\n",
    "    clusters[label].append((sent, prob))\n",
    "clusters = {k: v for _, k, v in sorted([(len(v), k, v) for k, v in clusters.items()])}\n",
    "\n",
    "with open('tsdae.csv', 'w') as f:\n",
    "    f.write(f\"CLUSTER_COUNT={len(clusters)}\\n\")\n",
    "    for k, v in clusters.items():\n",
    "        f.write(f\"\\nCluster {k:03d}:\\n\")\n",
    "        for s, p in v:\n",
    "            f.write(s.metadata['text'])\n",
    "            f.write('\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
