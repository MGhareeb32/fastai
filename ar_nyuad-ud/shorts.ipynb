{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "02d5f3e1-8939-42d7-99fa-3ea8a80f8ae9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SENTENCE.serialize()=\n",
      "# sent_id = 20000715_AFP_ARB.0075:5\n",
      "# text = وتعذر لمتحدثة باسم وزارة الدفاع الالمانية ان تؤكد اليوم السبت هذه المعلومات .\n",
      "# text_bw = wtE*r lmtHdvp bAsm wzArp AldfAE AlAlmAnyp An t&kd Alywm Alsbt h*h AlmElwmAt .\n",
      "1-2\tوتعذر\t_\t_\t_\t_\t_\t_\t_\t_\n",
      "1\tو\tw\tCCONJ\tCONJ\t_\t2\tcc\t_\tbw=wa\n",
      "2\tتعذر\ttaEa*~ar_1\tVERB\tPV+PVSUFF_SUBJ:3MS\tAspect=Perf|Gender=Masc|Mood=Ind|Number=Sing|Person=3|Voice=Act\t0\troot\t_\tbw=taEa*~ara\n",
      "3-4\tلمتحدثة\t_\t_\t_\t_\t_\t_\t_\t_\n",
      "3\tل\tl\tADP\tPREP\tAdpType=Prep\t4\tcase\t_\tbw=li\n",
      "4\tمتحدثة\tmutaHad~iv_1\tNOUN\tNOUN+NSUFF_FEM_SG+CASE_INDEF_GEN\tCase=Gen|Definite=Ind|Gender=Fem|Number=Sing\t2\tobj\t_\tbw=mutaHad~ivapK\n",
      "5-6\tباسم\t_\t_\t_\t_\t_\t_\t_\t_\n",
      "5\tب\tb\tADP\tPREP\tAdpType=Prep\t6\tcase\t_\tbw=bi\n",
      "6\tاسم\t{isom_1\tNOUN\tNOUN+CASE_DEF_GEN\tCase=Gen|Definite=Com|Gender=Masc|Number=Sing\t4\tobj\t_\tbw={isomi\n",
      "7\tوزارة\twizArap_1\tNOUN\tNOUN+NSUFF_FEM_SG+CASE_DEF_GEN\tCase=Gen|Definite=Com|Gender=Fem|Number=Sing\t6\tnmod:poss\t_\tbw=wizArapi\n",
      "8\tالدفاع\tdifAE_1\tNOUN\tDET+NOUN+CASE_DEF_GEN\tCase=Gen|Definite=Def|Gender=Masc|Number=Sing\t7\tnmod:poss\t_\tbw=AldifAEi\n",
      "9\tالالمانية\t>alomAniy~_1\tADJ\tDET+ADJ+NSUFF_FEM_SG+CASE_DEF_GEN\tCase=Gen|Definite=Def|Gender=Fem|Number=Sing\t7\tamod\t_\tbw=Al>alomAniy~api\n",
      "10\tان\t>ano_1\tSCONJ\tSUB_CONJ\t_\t11\tmark\t_\tbw=>ano\n",
      "11\tتؤكد\t>ak~ad_1\tVERB\tIV3FS+IV+IVSUFF_MOOD:S\tAspect=Imp|Gender=Fem|Mood=Sub|Number=Sing|Person=3|Voice=Act\t2\txcomp\t_\tbw=tu&ak~ida\n",
      "12\tاليوم\tyawom_1\tNOUN\tDET+NOUN+CASE_DEF_ACC\tCase=Acc|Definite=Def|Gender=Masc|Number=Sing\t11\tnmod\t_\tbw=Alyawoma\n",
      "13\tالسبت\tsabot_1\tNOUN\tDET+NOUN+CASE_DEF_ACC\tCase=Acc|Definite=Def|Gender=Masc|Number=Sing\t12\tnmod\t_\tbw=Alsabota\n",
      "14\tهذه\th`*A_1\tDET\tDEM_PRON_F\tDefinite=Ind|Gender=Fem|Number=Sing\t15\tdet\t_\tbw=h`*ihi\n",
      "15\tالمعلومات\tmaEoluwm_1\tNOUN\tDET+NOUN+NSUFF_FEM_PL+CASE_DEF_ACC\tCase=Acc|Definite=Def|Gender=Fem|Number=Plur\t11\tobj\t_\tbw=AlmaEoluwmAti\n",
      "16\t.\tDEFAULT\tPUNCT\tPUNC\t_\t2\tpunct\t_\tbw=.\n",
      "\n",
      "\n",
      "SENTENCE[1]=\n",
      "{\n",
      "  \"id\": 1,\n",
      "  \"form\": \"و\",\n",
      "  \"lemma\": \"w\",\n",
      "  \"upos\": \"CCONJ\",\n",
      "  \"xpos\": \"CONJ\",\n",
      "  \"feats\": null,\n",
      "  \"head\": 2,\n",
      "  \"deprel\": \"cc\",\n",
      "  \"deps\": null,\n",
      "  \"misc\": {\n",
      "    \"bw\": \"wa\"\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "!pip3 install -Uqq conllu tabulate\n",
    "# data loading\n",
    "import conllu\n",
    "import json\n",
    "\n",
    "def dict_prettify(token):\n",
    "    return json.dumps(token, indent=2, ensure_ascii=False)\n",
    "\n",
    "def corpus_load(path):\n",
    "    with open(path, 'r') as file:\n",
    "        return conllu.parse(file.read())\n",
    "    return None\n",
    "\n",
    "corpus_train = corpus_load('train.conllu')\n",
    "corpus_dev = corpus_load('dev.conllu')\n",
    "print(f\"SENTENCE.serialize()=\\n{corpus_train[10].serialize()}\")\n",
    "print(f\"SENTENCE[1]=\\n{dict_prettify(corpus_train[10][1])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "98f01c21-4e16-4f7b-8d4d-9847a3a449e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "تشكل خطراً على جيران ها\n",
      "تتخذ ها في الساعات الحرجة\n",
      "ما زالت في بدايات ها\n",
      "أن نقدم ل هم الدعم\n",
      "افاد مراسل وكالة فرانس برس\n",
      "ينفذ ها الشباب في فلسطين\n",
      "يتزعم ه اسامة بن لادن\n",
      "خاض ها البلدان عام 1962\n",
      "تؤدي إلى مقتل مواطنين أبرياء\n",
      "لا ينتمون إلى الحزب الحاكم\n",
      "اذا تمكنا من تحقيق تقدم\n",
      "س يضم قبرص إلي ه\n",
      "يبدأ خفض الرسوم الجمركية تدريجياً\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "def _tree_get_subsentence(node, is_root, skip_cond, subsentence):\n",
    "    if skip_cond is not None and skip_cond(node):\n",
    "        return\n",
    "    token = node.token\n",
    "    head_dist = token['head'] - token['id'] if not is_root else 0\n",
    "    deprel = token['deprel'] if not is_root else 'root'\n",
    "    subsentence[token['id']] = (token['id'], token['form'], token['lemma'],\n",
    "                                token['upos'], token['head'], deprel, token['xpos'], \n",
    "                                token['feats'], head_dist)\n",
    "    for ch in node.children:\n",
    "        _tree_get_subsentence(ch, False, skip_cond, subsentence)\n",
    "\n",
    "def tree_get_subsentence(node, skip_cond=None):\n",
    "    subsentence = {}\n",
    "    _tree_get_subsentence(node, True, skip_cond, subsentence)\n",
    "    subsentence = sorted([(k, v) for k, v in subsentence.items()])\n",
    "    if len(subsentence) > 0 and subsentence[-1][0] - subsentence[0][0] + 1 != len(subsentence):\n",
    "        return None\n",
    "    for (k, v) in subsentence:\n",
    "        if v[0] + v[-1] < subsentence[0][0] or v[0] + v[-1] > subsentence[-1][0]:\n",
    "            print(subsentence)\n",
    "            return None\n",
    "    return [i2 for (i1, i2) in subsentence]\n",
    "\n",
    "def _tree_get_subsentences_of_len(node, len_range, root_cond, skip_cond, result):\n",
    "    if root_cond is None or root_cond(node):\n",
    "        ss = tree_get_subsentence(node, skip_cond)\n",
    "        if ss is not None and len_range[0] <= len(ss) and len(ss) < len_range[1]:\n",
    "            result.append(ss)\n",
    "    for ch in node.children:\n",
    "        _tree_get_subsentences_of_len(ch, len_range, root_cond, skip_cond, result)\n",
    "\n",
    "def tree_get_subsentences_of_len(node, len_range, root_cond=None, skip_cond=None):\n",
    "    result = []\n",
    "    _tree_get_subsentences_of_len(node, len_range, root_cond, skip_cond, result)\n",
    "    return result\n",
    "\n",
    "def corpus_get_short_sentences(corpus):\n",
    "    for s in corpus:\n",
    "        tree = s.to_tree()\n",
    "        for ss in tree_get_subsentences_of_len(\n",
    "            tree, (5, 6),\n",
    "            root_cond=lambda n: n.token['upos'] == 'VERB',\n",
    "            skip_cond=lambda n: n.token['upos'] == 'PUNCT' or '،' in n.token['form']):\n",
    "            yield ss\n",
    "\n",
    "random.seed(1)\n",
    "for ss in corpus_get_short_sentences(random.sample(corpus_dev, 100)):\n",
    "    print(' '.join([f\"{v[1]}\" for v in ss]))\n",
    "    # print(' '.join([f\"{v[1]}.{v[2]}{v[3]:+d}\" for v in ss]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "36c17f44-7852-4cc9-93f5-2f439d486241",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = list(corpus_get_short_sentences(corpus_train))\n",
    "dev = list(corpus_get_short_sentences(corpus_dev))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7b658c97-f83f-4f24-b17f-cf214d23a775",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2030\n",
      "260\n"
     ]
    }
   ],
   "source": [
    "print(len(train))\n",
    "print(len(dev))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d1edfdb5-4a2c-47e0-a962-463ae9223525",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentences_to_file(filename, sentences, sep='\\t'):\n",
    "    with open(filename, 'w') as f:\n",
    "        f.write(f\"sent_id{sep}token_id{sep}form{sep}lemma{sep}upos{sep}head_id{sep}deprel{sep}xpos{sep}feats{sep}head_dist\\n\")\n",
    "        for i, s in enumerate(sentences):\n",
    "            for w in s:\n",
    "                f.write(f\"{i}\")\n",
    "                for v in w:\n",
    "                    f.write(f\"{sep}{v}\")\n",
    "                f.write(\"\\n\")\n",
    "\n",
    "sentences_to_file('short_dev.csv', dev)\n",
    "sentences_to_file('short_train.csv', train)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
